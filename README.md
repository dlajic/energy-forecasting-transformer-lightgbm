
# âš¡ï¸ Energy Forecasting with Transformer & LightGBM

Ein Machine-Learning-Projekt zur Vorhersage des stÃ¤dtischen Energieverbrauchs auf Basis von Wetter- und Verbrauchsdaten aus Chicago. Zwei ModellansÃ¤tze wurden implementiert und verglichen: ein Transformer-Modell (Deep Learning) und ein LightGBM-Modell (Gradient Boosting).

---

## ğŸ“¸ Live-Demo

> âœ¨ **Live-Dashboard**:  
> ğŸ‘‰ [Streamlit App starten](https://your-deployment-link.com)  
>  
> ![Demo](assets/demo.gif)

---

## ğŸ“‚ ProjektÃ¼berblick

- **Ziel**: Zeitreihen-Vorhersage des Energieverbrauchs auf Basis von Temperaturdaten.
- **Daten**: Ã–ffentliche Verbrauchs- und Temperaturdaten aus Chicago.
- **Modelle**: Transformer (PyTorch) & LightGBM (Scikit-Learn).
- **Workflow**: Datenaufbereitung â†’ Feature Engineering â†’ Modelltraining â†’ Evaluation â†’ Deployment mit Streamlit.

---

## ğŸ“ˆ Ergebnisse

| Modell      | RMSE     | MAE      | MAPE    |
|-------------|----------|----------|---------|
| Transformer | XX.XX    | XX.XX    | XX.X %  |
| LightGBM    | XX.XX    | XX.XX    | XX.X %  |

- Transformer zeigt Vorteile bei langfristigen Trends.
- LightGBM ist robuster bei begrenzten Daten und schneller im Training.

> ğŸ“Š Siehe Vergleichsplots in `lightgbm_model/results/` und `transformer_model/results/`

---

## ğŸ§  Modellarchitektur & Parameterwahl

### Transformer
- Multi-Head Attention, Positional Encoding, Dropout
- Getestete Varianten: Embedding-Typen, Weight Decay, Dropout-Raten
- Trainings-Monitoring: `training_plot.png`, Metriken als JSON

### LightGBM
- Extensive Gridsearch: `num_leaves`, `min_child_samples`, `learning_rate`, u.v.m.
- Feature Importance zur Reduktion irrelevanter Features
- Learning Curves, FehlerverlÃ¤ufe dokumentiert

---

## ğŸ§¾ Datengrundlage

- Verbrauchsdaten: `data/raw/COMED_hourly.csv`
- Temperaturdaten: `data/external/Temperature_chicago.csv`
- Vorverarbeitet in: `data/processed/energy_consumption_aggregated_cleaned.csv`

> CSV-Format fÃ¼r eigene Daten:  
> `timestamp, consumption, temperature`

---

## ğŸ—‚ï¸ Ordnerstruktur

```bash
energy-forecasting-transformer-lightgbm/
â”‚
â”œâ”€â”€ data/                     # Roh-, externe und bereinigte Daten
â”‚   â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ external/
â”‚   â””â”€â”€ processed/
â”‚
â”œâ”€â”€ notebooks/               # EDA & Modellprototyping (LightGBM + Transformer)
â”‚   â”œâ”€â”€ eda/
â”‚   â”œâ”€â”€ lightgbm/
â”‚   â””â”€â”€ transformer/
â”‚
â”œâ”€â”€ scripts/                 # Preprocessing & Konfiguration
â”‚   â”œâ”€â”€ data_preprocessing/
â”‚   â””â”€â”€ config_main.py
â”‚
â”œâ”€â”€ lightgbm_model/          # LightGBM Modell, Skripte, Ergebnisse
â”‚   â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ results/
â”‚   â””â”€â”€ scripts/
â”‚       â”œâ”€â”€ train/
â”‚       â””â”€â”€ eval/
â”‚
â”œâ”€â”€ transformer_model/       # Transformer-Modell inkl. Training/Eval/Utils
â”‚   â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ results/
â”‚   â””â”€â”€ scripts/
â”‚       â”œâ”€â”€ training/
â”‚       â”œâ”€â”€ evaluation/
â”‚       â””â”€â”€ utils/
â”‚
â”œâ”€â”€ streamlit_simulation/    # Streamlit App zur Modellvorhersage
â”‚   â””â”€â”€ app.py
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ requirements_lgbm.txt
â”œâ”€â”€ setup.py
â””â”€â”€ README.md
```

---

## ğŸš€ Installation & AusfÃ¼hrung

### Voraussetzungen

- Python â‰¥ 3.9
- Virtuelle Umgebung empfohlen (z.â€¯B. `venv` oder `conda`)

### Setup

```bash
git clone https://github.com/dlajic/energy-forecasting-transformer-lightgbm.git
cd energy-forecasting-transformer-lightgbm
pip install -r requirements.txt
```

### Datenvorverarbeitung

```bash
python scripts/data_preprocessing/preprocess_data.py
```

### Modelltraining

```bash
# LightGBM
python lightgbm_model/scripts/train/train_lightgbm.py

# Transformer
python transformer_model/scripts/training/train.py
```

### Evaluation

```bash
python lightgbm_model/scripts/eval/eval_lightgbm.py
python transformer_model/scripts/evaluation/evaluate.py
```

### Streamlit App starten

```bash
streamlit run streamlit_simulation/app.py
```

---

## ğŸ§ª Reproduzierbarkeit

- Alle Schritte sind modular und automatisiert aufrufbar.
- Eigene Daten im CSV-Format (`timestamp, consumption, temperature`) kÃ¶nnen direkt Ã¼ber das Preprocessing-Skript genutzt werden.

---

## ğŸ”­ Ausblick

- [ ] Weitere StÃ¤dte / Klimazonen integrieren
- [ ] Modell-Deployment als REST API (z.â€¯B. mit FastAPI)
- [ ] Automatisierte Hyperparameteroptimierung (Optuna)

---

## ğŸ‘¤ Autor

**Damir Lajic**  
[GitHub](https://github.com/dlajic) Â· [LinkedIn](https://www.linkedin.com/in/dein-name)
